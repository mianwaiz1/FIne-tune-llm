{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d2a337-c3ef-4cf0-aa4a-c2cda55ba7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine_tune_lung_cancer.ipynb\n",
    "\n",
    "# ============================\n",
    "# ðŸ“˜ Fine-Tuning FLAN-T5(llm model) on Lung Cancer Q/A \n",
    "# ============================\n",
    "# check readme.md for brief information (how this code is working)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ad5098-36b3-419f-9bea-fa18937c2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages \n",
    "!pip install torch==2.2.2 transformers==4.41.2 datasets==2.20.0 evaluate==0.4.2 numpy==1.26.4 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5f90a1",
   "metadata": {},
   "source": [
    "json â†’ handle dataset format.\n",
    "Dataset â†’ organize data for training.\n",
    "AutoTokenizer â†’ convert text into tokens.\n",
    "AutoModelForSeq2SeqLM â†’ load a pretrained seq2seq model.\n",
    "Seq2SeqTrainingArguments â†’ set training parameters.\n",
    "Seq2SeqTrainer â†’ train/evaluate the model easily.\n",
    "torch â†’ core ML computations and GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5fd860-a868-455b-8c24-588961583783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import json\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305aab0b",
   "metadata": {},
   "source": [
    "loading dataset from lung_cancer.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7899e781-f635-429e-98a9-bc2597b17d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSONL dataset\n",
    "def load_dataset(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                data.append(json.loads(line))\n",
    "    return Dataset.from_list(data)\n",
    "\n",
    "dataset = load_dataset(\"lung_cancer.jsonl\")  # <-- replace with your dataset path\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89ab4d1",
   "metadata": {},
   "source": [
    "loading model of google flan t5 which is small and faster and accurate \n",
    "using autotokenizer because it chooses the best tokenzier based on your model\n",
    "making model seq2seq language modeling for QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d9271-cd18-4d23-910d-55519fdb9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading model and numbers of tokens \n",
    "model_name = \"google/flan-t5-small\"   # small and efficient\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d13a7f",
   "metadata": {},
   "source": [
    "in preprocessing we give the input and output to model for fine tuning max lengths defines maximum numbers of tokens which tokenizer will keep for each input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d2c78-61cd-4315-bfad-9006e97fd0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing \n",
    "def preprocess(batch):\n",
    "    inputs = tokenizer(batch[\"input\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(batch[\"output\"], max_length=128, truncation=True, padding=\"max_length\")\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True)\n",
    "tokenized_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3309971c",
   "metadata": {},
   "source": [
    "spliting data into training and testing to check our model is working right and accurate or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a433549-0a22-438d-b4d6-5036a3a11a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting into train and test\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6f85e5",
   "metadata": {},
   "source": [
    "asigning arguments for training our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440943c2-3e9f-4ecd-94c3-953cdccfe872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training arguments \n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",   # âœ… correct arg\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fc4d8b",
   "metadata": {},
   "source": [
    "using huggging face seq2seq trainer which will automatically train our model accordng to the model and args and divides them into training and testing variables for training and evaluating fine tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb6ea3f-6528-49e7-8320-d1bc50fdcf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer setup\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=split_dataset[\"train\"],\n",
    "    eval_dataset=split_dataset[\"test\"],\n",
    "    tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b317f",
   "metadata": {},
   "source": [
    "train our modela and then save it as fine_tuned_lung_cancer model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7c8c20-abe6-47c4-8fec-3151985740be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and save model as fine_tuned_lung_cancer\n",
    "trainer.train()\n",
    "model.save_pretrained(\"./fine_tuned_lung_cancer\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_lung_cancer\")\n",
    "\n",
    "print(\"âœ… Training complete! Model saved in ./fine_tuned_lung_cancer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
